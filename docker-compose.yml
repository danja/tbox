services:
  ssh-server:
    build: .
    ports:
      - "2222:22"
    volumes:
      - ./projects:/home/projects
      - ./config/scripts:/scripts:ro
      - node_modules:/home/projects/node_modules
      - npm_cache:/root/.npm
      - ssh_config:/root/.ssh
    environment:
      - NODE_ENV=production
      - NODE_TLS_REJECT_UNAUTHORIZED=0
    networks:
      - tbox-network
    healthcheck:
      test: [ "CMD", "pgrep", "sshd" ]
      interval: 30s
      timeout: 10s
      retries: 3

  app:
    build:
      context: ./services/app
    ports:
      - "4010:8311"
    networks:
      - tbox-network
    depends_on:
      fuseki:
        condition: service_healthy
    environment:
      - FUSEKI_URL=http://fuseki:3030
      - FUSEKI_DATASET_1=ds
      - FUSEKI_DATASET_2=test-mem
      - FUSEKI_DATASET_3=test-db
      - FUSEKI_DATASET_4=semem
      - FUSEKI_DATASET_5=squirt
      - FUSEKI_DATASET_6=tia
      - FUSEKI_DATASET_7=claudiob
      - FUSEKI_DATASET_8=danja
      - FUSEKI_DATASET_9=danbri
      - FUSEKI_DATASET_10=hyperdata

  fuseki:
    image: stain/jena-fuseki:latest
    user: "0:0" # root
    ports:
      - "4030:3030"
    volumes:
      - ./data/fuseki:/fuseki/databases
      - ./config/fuseki:/fuseki/configuration:rw
    environment:
      - ADMIN_PASSWORD=admin123
      - FUSEKI_CONFIG_FILE=/fuseki/configuration/config.ttl
      - FUSEKI_BASE=/fuseki
      - SHIRO_INI=/fuseki/configuration/shiro.ini
      - JVM_ARGS=-Xmx2048m -Xms2048m
    networks:
      - tbox-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:3030/$/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  semem:
    image: node:20-alpine
    tty: true
    stdin_open: true
    container_name: semem
    environment:
      - NODE_ENV=production
      - PORT=4100
      - UI_PORT=4120
      - REDIRECT_PORT=4110
      - NODE_TLS_REJECT_UNAUTHORIZED=0
      - CONFIG_FILE=/app/config/config.js
    ports:
      - "4100:4100"
      - "4110:4110"
      - "4120:4120"
    volumes:
      - ./projects/semem:/app
      - ./config/semem:/app/config
    working_dir: /app
    command: sh -c "npm install && npm start"
    networks:
      - tbox-network
    depends_on:
      fuseki:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--spider", "http://localhost:4100/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  nginx:
    image: nginx:alpine
    ports:
      - "4000:4000"
      - "4200:4200"
      - "4210:4210"
      - "4220:4220"
      - "4240:4240"
      - "4250:4250"
      - "4280:4280"
      - "4290:4290"
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./config/nginx/conf.d:/etc/nginx/conf.d:ro
      - ./services/web/public:/usr/share/nginx/html:ro
      - ./projects:/projects:ro
    networks:
      - tbox-network
    depends_on:
      app:
        condition: service_started
      fuseki:
        condition: service_healthy
    restart: unless-stopped

  xmpp:
    #   image: prosody/prosody

    build:
      context: . # Build context is the root of the tbox project
      dockerfile: Dockerfile.prosody # Use your custom Dockerfile
    ports:
      - "5222:5222"
      - "5269:5269"
      - "5280:5280" # Standard HTTP
      - "5281:5281" # Standard HTTPS if enabled
      - "5282:5282" # For http-monitor if you intend to use it on this port
    volumes:
      # moved to Dockerfile.prosody
      #     - ./config/prosody/prosody.cfg.lua:/etc/prosody/prosody.cfg.lua:ro
      - ./config/certs:/etc/prosody/certs:rw # CRITICAL: Must be read-write for the script to create/update certs and dh.pem
      #   - ./config/prosody/conf.d:/etc/prosody/conf.d:ro
      # Mount the entrypoint and initialization scripts
      #   - ./config/prosody/docker-entrypoint.sh:/usr/local/bin/docker-entrypoint.sh:ro
      #   - ./config/prosody/ensure-prosody-certs.sh:/usr/local/bin/ensure-prosody-certs.sh:ro
      #   - ./config/prosody/prosody-init-users.sh:/usr/local/bin/prosody-init-users.sh:ro
    environment:
      - PROSODY_DOMAIN=xmpp # Set your desired domain here (e.g., xmpp)
      - PROSODY_ADMIN_JID=admin@xmpp # Align with PROSODY_DOMAIN
      - PROSODY_ADMIN_PASSWORD=admin123
      - NODE_TLS_REJECT_UNAUTHORIZED=0
    command: [ "prosody" ] # Pass the 'prosody' command as arguments to the entrypoint script
    networks:
      - tbox-network
    restart: unless-stopped

  monitor:
    build:
      context: ./services/monitor
    ports:
      - "4040:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - FUSEKI_URL=http://tbox-fuseki-1:3030
    depends_on:
      - app
      - fuseki
      - xmpp
    networks:
      - tbox-network

  # Add these services to your docker-compose.yml under the services section

  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: tbox-otel-collector
    command: [ "--config=/etc/otel-collector-config.yaml" ]
    volumes:
      - ./config/otel/otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
    ports:
      - "4317:4317" # OTLP gRPC receiver
      - "4318:4318" # OTLP HTTP receiver
      - "8889:8889" # Prometheus metrics exporter
      - "13133:13133" # Health check extension
      - "55679:55679" # zPages extension
    depends_on:
      - jaeger
    networks:
      - tbox-network

  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: tbox-jaeger
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    ports:
      - "16686:16686" # Jaeger UI
      - "14250:14250" # gRPC receiver
    networks:
      - tbox-network

  prometheus:
    image: prom/prometheus:latest
    container_name: tbox-prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
    volumes:
      - ./config/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    ports:
      - "9090:9090" # Prometheus UI
    networks:
      - tbox-network

networks:
  tbox-network:
    driver: bridge

volumes:
  node_modules:
  npm_cache:
  ssh_config:
  prometheus_data:
  semem_node_modules:
  data:
    driver: local
