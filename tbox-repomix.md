This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document.
Generated by Repomix on: 2025-03-29T18:40:22.266Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
- Pay special attention to the Repository Description. These contain important context and guidelines specific to this project.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: docs, **/_*, fuseki-data, node_modules, .git, *.log, **/jsdoc, **/media, **/*repomix*
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------
User Provided Header:
-----------------------
tbox source code

================================================================
Directory Structure
================================================================
app/
  app.js
certs/
  localhost.crt
config/
  certs/
    localhost.crt
  fuseki/
    databases/
      ds.ttl_
    examples/
      config-1-mem.ttl
      config-3-dataset-endpoints.ttl
      config-tdb1.ttl
      shiro.ini
    old-config/
      2025-03-28.ttlconfig.ttl
      a.ttl
      b.ttl
    config.ttl
    init.sh
    shiro.ini
  nginx/
    nginx.conf
  prosody/
    prosody.cfg.lua
  scripts/
    setup-repos.sh
fuseki/
  config.ttl
  shiro.ini
jena-fuseki-docker-5.3.0/
  docker-compose.yaml
  Dockerfile
  download.sh
  entrypoint.sh
  LICENSE
  log4j2.properties
  NOTICE
  README.md
monitor/
  Dockerfile
  index.js
  package.json
scripts/
  check_fuseki.sh
  clean-fuseki-locks.sh
  del2.sh
  delete-triples.sh
  rebuild-restart.sh
  restart-fuseki.sh
  ssh-entry.sh
  tbox.service
  test_fuseki-persistence.sh
services/
  app/
    src/
      app.js
    Dockerfile
    package.json
  monitor/
    src/
      index.js
      index.js.backup
    Dockerfile
    package.json
  web/
    public/
      index.html
.gitignore
about.md
config.ttl
docker-compose.override.yml
docker-compose.yml
Dockerfile
Dockerfile copy
Dockerfile.prosody
ecosystem.config.js
fuseki-service-old
fuseki.service
LICENSE
nginx.conf
package-ref.json
package.json
README.md
rebuild-start.sh
restart-dogbot.sh
restart.sh
simple-ssh-test.yml
tbox.service

================================================================
Files
================================================================

================
File: app/app.js
================
const express = require('express');
const app = express();
const port = 8311;

app.get('/', (req, res) => {
    const headers = JSON.stringify(req.headers, null, 2);
    res.send(`
        <pre>Request Headers:
        ${headers}</pre>
        <hr>
        Hello, Sandboxed World!
    `);
});

app.get('/health', (req, res) => {
    res.json({
        status: 'ok',
        time: new Date(),
        uptime: process.uptime()
    });
});

app.listen(port, '0.0.0.0', () => console.log(`Server running on port ${port}`));

================
File: certs/localhost.crt
================
-----BEGIN CERTIFICATE-----
MIIDiTCCAnGgAwIBAgIUJTcNoUREEMw+LGrwLpfZiejmGX4wDQYJKoZIhvcNAQEL
BQAwVDELMAkGA1UEBhMCaXQxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM
GEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDENMAsGA1UEAwwEdGJveDAeFw0yNDEx
MzAxODQyMTZaFw0yNTExMzAxODQyMTZaMFQxCzAJBgNVBAYTAml0MRMwEQYDVQQI
DApTb21lLVN0YXRlMSEwHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQx
DTALBgNVBAMMBHRib3gwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCH
8cCUXf89k7l6Yg1k/KvEUcwRhkLIGe/1jnfF737vf7ErL7cY3EEW5coo3OISWoPf
5ElHrO/RpiBGI5a9O1A6c/zCrzBRlWQVymOFlGRwnAr64QUDc1j/Xp43EDHG+otJ
99FNhjvbG/Td9+1zEURl19QFEoSaSwo8edQMMIYtlGR3lrnQoHBL4I0ZvvtmKh7q
9R9ooeQKmT+HDxQd2wBWPnhCUA0edk+WPnfxfMxY0q8pBo5hNsk1R29j4Bj7iTJX
M3+3QIzdTqnf/Ze6uIbQRXQYpz0+koyDsT22fVcEkxf+NlAFyenUslG5f+u8IWq7
gtwUcYfaT832YTPfnJSPAgMBAAGjUzBRMB0GA1UdDgQWBBRNAKxfTtwgCVmCPf92
LPuvLxxavTAfBgNVHSMEGDAWgBRNAKxfTtwgCVmCPf92LPuvLxxavTAPBgNVHRMB
Af8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAvzSy3GuHkFGMgkLXO895J7wWw
IEmWMLi9iQJvWWmT2S/P98jzBwsrJMRRR5jsx6iWdOSMdTlw9dd8IyYKVQU6KHdQ
urkZB47xRJ9AVStJ4Ptn01hYLfPG0nGVmwpIZD0pNqoyLSbMA4wbrnQich0+/jSL
HUrUjqbIWyYgCGrHiLf+QaBPSCyy2Qoqqe1+Rox4eKzjWuy9G6cvM7o/NS3JqB23
RD0dV+ylW1KTMSyMLQRa/I7khMYE7igaVplGQKW4pvhprUgHc3w/IUi0XCfackiE
smb6TCJwUcUk0Nk9/bPAxRTOCCoCIEjwbFbbpZmHmDe7q5qRjljWSb0b+lac
-----END CERTIFICATE-----

================
File: config/certs/localhost.crt
================
-----BEGIN CERTIFICATE-----
MIIDiTCCAnGgAwIBAgIUJTcNoUREEMw+LGrwLpfZiejmGX4wDQYJKoZIhvcNAQEL
BQAwVDELMAkGA1UEBhMCaXQxEzARBgNVBAgMClNvbWUtU3RhdGUxITAfBgNVBAoM
GEludGVybmV0IFdpZGdpdHMgUHR5IEx0ZDENMAsGA1UEAwwEdGJveDAeFw0yNDEx
MzAxODQyMTZaFw0yNTExMzAxODQyMTZaMFQxCzAJBgNVBAYTAml0MRMwEQYDVQQI
DApTb21lLVN0YXRlMSEwHwYDVQQKDBhJbnRlcm5ldCBXaWRnaXRzIFB0eSBMdGQx
DTALBgNVBAMMBHRib3gwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQCH
8cCUXf89k7l6Yg1k/KvEUcwRhkLIGe/1jnfF737vf7ErL7cY3EEW5coo3OISWoPf
5ElHrO/RpiBGI5a9O1A6c/zCrzBRlWQVymOFlGRwnAr64QUDc1j/Xp43EDHG+otJ
99FNhjvbG/Td9+1zEURl19QFEoSaSwo8edQMMIYtlGR3lrnQoHBL4I0ZvvtmKh7q
9R9ooeQKmT+HDxQd2wBWPnhCUA0edk+WPnfxfMxY0q8pBo5hNsk1R29j4Bj7iTJX
M3+3QIzdTqnf/Ze6uIbQRXQYpz0+koyDsT22fVcEkxf+NlAFyenUslG5f+u8IWq7
gtwUcYfaT832YTPfnJSPAgMBAAGjUzBRMB0GA1UdDgQWBBRNAKxfTtwgCVmCPf92
LPuvLxxavTAfBgNVHSMEGDAWgBRNAKxfTtwgCVmCPf92LPuvLxxavTAPBgNVHRMB
Af8EBTADAQH/MA0GCSqGSIb3DQEBCwUAA4IBAQAvzSy3GuHkFGMgkLXO895J7wWw
IEmWMLi9iQJvWWmT2S/P98jzBwsrJMRRR5jsx6iWdOSMdTlw9dd8IyYKVQU6KHdQ
urkZB47xRJ9AVStJ4Ptn01hYLfPG0nGVmwpIZD0pNqoyLSbMA4wbrnQich0+/jSL
HUrUjqbIWyYgCGrHiLf+QaBPSCyy2Qoqqe1+Rox4eKzjWuy9G6cvM7o/NS3JqB23
RD0dV+ylW1KTMSyMLQRa/I7khMYE7igaVplGQKW4pvhprUgHc3w/IUi0XCfackiE
smb6TCJwUcUk0Nk9/bPAxRTOCCoCIEjwbFbbpZmHmDe7q5qRjljWSb0b+lac
-----END CERTIFICATE-----

================
File: config/fuseki/databases/ds.ttl_
================
@prefix :      <#> .
@prefix fuseki: <http://jena.apache.org/fuseki#> .
@prefix rdf:   <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix tdb2:  <http://jena.apache.org/2016/tdb#> .

:service_tdb_all a fuseki:Service ;
    fuseki:name "ds" ;
    fuseki:endpoint [ 
        fuseki:operation fuseki:query ;
        fuseki:name "query"
    ] ;
    fuseki:endpoint [
        fuseki:operation fuseki:update ;
        fuseki:name "update"
    ] ;
    fuseki:dataset [
        a tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/ds"
    ] .

================
File: config/fuseki/examples/config-1-mem.ttl
================
## Licensed under the terms of http://www.apache.org/licenses/LICENSE-2.0

PREFIX :        <#>
PREFIX fuseki:  <http://jena.apache.org/fuseki#>
PREFIX rdf:     <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs:    <http://www.w3.org/2000/01/rdf-schema#>
PREFIX ja:      <http://jena.hpl.hp.com/2005/11/Assembler#>

[] rdf:type fuseki:Server ;
   fuseki:services (
     :service
   ) .

## Service description for "/dataset" with all endpoints.
## e.g.
##   GET /dataset/query?query=...
##   GET /dataset/get?default (SPARQL Graph Store Protocol)

:service rdf:type fuseki:Service ;
    fuseki:name "dataset" ;

    ## The  GET /dataset?query= variants
    fuseki:endpoint [ fuseki:operation fuseki:query ; ] ;
    ## gsp-rw covers gsp-r and upload.
    fuseki:endpoint [ fuseki:operation fuseki:update ; ] ;
    fuseki:endpoint [ fuseki:operation fuseki:gsp-rw ; ] ;
    ## RDF Patch
    fuseki:endpoint [ fuseki:operation fuseki:patch ; ] ;

    fuseki:endpoint [ 
        fuseki:operation fuseki:query ;
        fuseki:name "sparql" 
    ];
    fuseki:endpoint [
        fuseki:operation fuseki:query ;
        fuseki:name "query" 
    ] ;
    fuseki:endpoint [
        fuseki:operation fuseki:update ;
        fuseki:name "update"
    ] ;
    fuseki:endpoint [
        fuseki:operation fuseki:gsp-r ;
        fuseki:name "get"
    ] ;
    fuseki:endpoint [ 
        fuseki:operation fuseki:gsp-rw ; 
        fuseki:name "data"
    ] ; 
    fuseki:endpoint [
        ## RDF Patch
        fuseki:operation fuseki:patch ;
        fuseki:name "patch"
    ] ; 
    fuseki:dataset :dataset ;
    .

# Transactional in-memory dataset.
:dataset rdf:type ja:MemoryDataset ;
    ## Optional load with data on start-up
    ## ja:data "data1.trig";
    ## ja:data "data2.trig";
    .

================
File: config/fuseki/examples/config-3-dataset-endpoints.ttl
================
## Licensed under the terms of http://www.apache.org/licenses/LICENSE-2.0

PREFIX :        <#>
PREFIX fuseki:  <http://jena.apache.org/fuseki#>
PREFIX rdf:     <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs:    <http://www.w3.org/2000/01/rdf-schema#>
PREFIX ja:      <http://jena.hpl.hp.com/2005/11/Assembler#>

[] rdf:type fuseki:Server ;
   fuseki:services (
     :service
   ) .

## Service description for "/dataset" with all endpoints.
## Operations are on the dataset e.g. /dataset?query=


:service rdf:type fuseki:Service ;
    fuseki:name "dataset" ;
##     fuseki:endpoint [
##         fuseki:operation fuseki:query ;
##         fuseki:name "" # This is optional.
##     ] ;
    fuseki:endpoint [ fuseki:operation fuseki:query ; ] ;
    fuseki:endpoint [ fuseki:operation fuseki:update ; ] ;
    fuseki:endpoint [ fuseki:operation fuseki:gsp-r ;  ] ;
    fuseki:endpoint [ fuseki:operation fuseki:gsp-rw ; ] ; 
    fuseki:endpoint [ fuseki:operation fuseki:upload ; ] ; 
    fuseki:endpoint [ fuseki:operation fuseki:patch ; ] ; 
    fuseki:dataset :dataset ;
    .

# Transactional in-memory dataset.
:dataset rdf:type ja:MemoryDataset .

================
File: config/fuseki/examples/config-tdb1.ttl
================
## Licensed under the terms of http://www.apache.org/licenses/LICENSE-2.0

PREFIX :        <#>
PREFIX fuseki:  <http://jena.apache.org/fuseki#>
PREFIX rdf:     <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs:    <http://www.w3.org/2000/01/rdf-schema#>
PREFIX ja:      <http://jena.hpl.hp.com/2005/11/Assembler#>
PREFIX tdb1:    <http://jena.hpl.hp.com/2008/tdb#>

[] rdf:type fuseki:Server ;
   fuseki:services (
     :service
   ) .

## Service description for "/dataset"
## with a TDB1 dataset

:service rdf:type fuseki:Service ;
    fuseki:name "dataset" ;
    fuseki:endpoint [ 
        fuseki:operation fuseki:query ;
        fuseki:name "sparql" 
    ];
    fuseki:endpoint [
        fuseki:operation fuseki:query ;
        fuseki:name "query" 
    ] ;
    fuseki:endpoint [
        fuseki:operation fuseki:update ;
        fuseki:name "update"
    ] ;
    fuseki:endpoint [
        fuseki:operation fuseki:gsp-r ;
        fuseki:name "get"
    ] ;
    fuseki:endpoint [ 
        fuseki:operation fuseki:gsp-rw ; 
        fuseki:name "data"
    ] ; 
    fuseki:endpoint [ 
        fuseki:operation fuseki:patch ;
        fuseki:name "patch"
    ] ; 
    fuseki:dataset :dataset ;
    .

:dataset_tdb1 rdf:type    tdb1:DatasetTDB ;
    tdb1:location "DB1" ;
    ## Optional - with union default for query and update WHERE matching.
    ## tdb2:unionDefaultGraph true ;
    .

================
File: config/fuseki/examples/shiro.ini
================
[users]
admin=admin123

[urls]
## Control functions open to anyone
/$/status = anon
/$/ping   = anon
/$/** = authcBasic,user[admin]
# Everything else
/**=anon

================
File: config/fuseki/old-config/2025-03-28.ttlconfig.ttl
================
@prefix :      <#> .
@prefix f: <http://jena.apache.org/fuseki#> .
@prefix rdf:   <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix tdb2:  <http://jena.apache.org/2016/tdb#> .
@prefix ja:    <http://jena.hpl.hp.com/2005/11/Assembler#> .

[] rdf:type f:Server ;
   f:services (
     :ds
     :test-mem
     :test-db
     :semem
     :hyperdata
   ) .

:test-mem rdf:type f:Service ;
    f:name                     "test-mem" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
    f:endpoint [
        f:operation          f:gsp-rw ;
        f:name              "data"
    ] ;
    f:dataset [
        rdf:type ja:MemoryDataset
    ] .

:ds rdf:type f:Service ;
    f:name                     "ds" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
    f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/ds"
    ] .

:semem rdf:type f:Service ;
    f:name                     "semem" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
       f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/semem"
    ] .

:test-db rdf:type f:Service ;
    f:name                     "test-db" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
       f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/test-db"
    ] .

:hyperdata rdf:type f:Service ;
    f:name "hyperdata" ;
   f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
    f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/hyperdata"
    ] .

================
File: config/fuseki/old-config/a.ttl
================
@prefix :      <#> .
@prefix fuseki: <http://jena.apache.org/fuseki#> .
@prefix rdf:   <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix tdb2:  <http://jena.apache.org/2016/tdb#> .
@prefix ja:    <http://jena.hpl.hp.com/2005/11/Assembler#> .

[] rdf:type fuseki:Server ;
   fuseki:services (
     :ds
     :semem
     :test-db
     :test-mem
   ) .

:test-mem rdf:type fuseki:Service ;
    fuseki:name                     "test-mem" ;
    fuseki:endpoint [
        fuseki:operation          fuseki:query ;
        fuseki:name              "query"
    ] ;
    fuseki:endpoint [
        fuseki:operation          fuseki:update ;
        fuseki:name              "update"
    ] ;
    fuseki:endpoint [
        fuseki:operation          fuseki:gsp-r ;
        fuseki:name              "get"
    ] ;
    fuseki:endpoint [
        fuseki:operation          fuseki:gsp-rw ;
        fuseki:name              "data"
    ] ;
    fuseki:dataset [
        rdf:type ja:MemoryDataset
    ] .

:ds rdf:type fuseki:Service ;
    fuseki:name                     "ds" ;
    fuseki:endpoint [
        fuseki:operation          fuseki:query ;
        fuseki:name              "query"
    ] ;
    fuseki:endpoint [
        fuseki:operation          fuseki:update ;
        fuseki:name              "update"
    ] ;
    fuseki:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/ds"
    ] .

:semem rdf:type fuseki:Service ;
    fuseki:name                     "semem" ;
    fuseki:endpoint [
        fuseki:operation          fuseki:query ;
        fuseki:name              "query"
    ] ;
    fuseki:endpoint [
        fuseki:operation          fuseki:update ;
        fuseki:name              "update"
    ] ;
    fuseki:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/semem"
    ] .

:test-db rdf:type fuseki:Service ;
    fuseki:name                     "test-db" ;
    fuseki:endpoint [
        fuseki:operation          fuseki:query ;
        fuseki:name              "query"
    ] ;
    fuseki:endpoint [
        fuseki:operation          fuseki:update ;
        fuseki:name              "update"
    ] ;
    fuseki:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/test-db"
    ] .

================
File: config/fuseki/old-config/b.ttl
================
@prefix :      <#> .
@prefix f: <http://jena.apache.org/fuseki#> .
@prefix rdf:   <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix tdb2:  <http://jena.apache.org/2016/tdb#> .
@prefix ja:    <http://jena.hpl.hp.com/2005/11/Assembler#> .

[] rdf:type f:Server ;
   f:services (
     :ds
     :test-mem
     :test-db
     :semem
     :hyperdata
   ) .

:test-mem rdf:type f:Service ;
    f:name                     "test-mem" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
    f:endpoint [
        f:operation          f:gsp-rw ;
        f:name              "data"
    ] ;
    f:dataset [
        rdf:type ja:MemoryDataset
    ] .

:ds rdf:type f:Service ;
    f:name                     "ds" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
    f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/ds"
    ] .

:semem rdf:type f:Service ;
    f:name                     "semem" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
       f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/semem"
    ] .

:test-db rdf:type f:Service ;
    f:name                     "test-db" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
       f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/test-db"
    ] .

:hyperdata rdf:type f:Service ;
    f:name "hyperdata" ;
   f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
    f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/hyperdata"
    ] .

================
File: config/fuseki/config.ttl
================
@prefix :      <#> .
@prefix f: <http://jena.apache.org/fuseki#> .
@prefix rdf:   <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix tdb2:  <http://jena.apache.org/2016/tdb#> .
@prefix ja:    <http://jena.hpl.hp.com/2005/11/Assembler#> .

[] rdf:type f:Server ;
   f:services (
     :ds
     :test-mem
     :test-db
     :semem
     :hyperdata
   ) .

:test-mem rdf:type f:Service ;
    f:name                     "test-mem" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
    f:endpoint [
        f:operation          f:gsp-rw ;
        f:name              "data"
    ] ;
    f:dataset [
        rdf:type ja:MemoryDataset
    ] .

:ds rdf:type f:Service ;
    f:name                     "ds" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
    f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/ds"
    ] .

:semem rdf:type f:Service ;
    f:name                     "semem" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
       f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/semem"
    ] .

:test-db rdf:type f:Service ;
    f:name                     "test-db" ;
    f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
       f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/test-db"
    ] .

:hyperdata rdf:type f:Service ;
    f:name "hyperdata" ;
   f:endpoint [
        f:operation          f:query ;
        f:name              "query"
    ] ;
    f:endpoint [
        f:operation          f:update ;
        f:name              "update"
    ] ;
    f:endpoint [
        f:operation f:gsp_rw ;
        f:name "data"
    ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/hyperdata"
    ] .

================
File: config/fuseki/init.sh
================
#!/bin/bash
# Clean up any stale lock files
rm -f /fuseki/system/tdb.lock
rm -f /fuseki/databases/*/tdb.lock

# Start Fuseki server
exec "$@"

================
File: config/fuseki/shiro.ini
================
[users]
admin=admin123

[urls]
## Control functions open to anyone
/$/status = anon
/$/ping   = anon
/$/** = authcBasic,user[admin]
# Everything else
/**=anon

================
File: config/nginx/nginx.conf
================
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    upstream app_server {
        server app:8311;
    }

    upstream fuseki_server {
        server fuseki:3030;
    }

    server {
        listen 4080;
        root /usr/share/nginx/html;
        index index.html;

        # CORS configuration
        add_header 'Access-Control-Allow-Origin' '*';
        add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, PUT, DELETE';
        add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';

        # Add for debugging
        access_log /var/log/nginx/access.log;
        error_log /var/log/nginx/error.log debug;

        location / {
            try_files $uri $uri/ /index.html;
        }

        location /api/ {
            if ($request_method = 'OPTIONS') {
                add_header 'Access-Control-Allow-Origin' '*';
                add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, PUT, DELETE';
                add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';
                add_header 'Access-Control-Max-Age' 1728000;
                add_header 'Content-Type' 'text/plain charset=UTF-8';
                add_header 'Content-Length' 0;
                return 204;
            }
            proxy_pass http://app_server;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }

        location /fuseki/ {
            if ($request_method = 'OPTIONS') {
                add_header 'Access-Control-Allow-Origin' '*';
                add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, PUT, DELETE';
                add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';
                add_header 'Access-Control-Max-Age' 1728000;
                add_header 'Content-Type' 'text/plain charset=UTF-8';
                add_header 'Content-Length' 0;
                return 204;
            }
            proxy_pass http://fuseki_server/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}

================
File: config/prosody/prosody.cfg.lua
================
admins = { "admin@localhost" }

modules_enabled = {
    "roster"; "saslauth"; "tls"; "dialback"; "disco";
    "posix"; "ping"; "register";
    "admin_adhoc"; "offline"; "c2s"; "s2s";
    "muc"; "muc_mam"; "vcard";
}

-- Authentication settings
authentication = "internal_plain"
allow_unencrypted_plain_auth = true
c2s_require_encryption = false
s2s_require_encryption = false

-- Registration settings
allow_registration = true
-- Conflict management - if a second connection with the same resource connects, kick the first one
conflict_resolve = "kick_oldest"

-- Logging settings
http_monitoring_interval = 30

http_upload_file_size_limit = 104857600
http_upload_expire_after = 60 * 60 * 24 * 7
http_upload_path = "/var/lib/prosody/http_upload"

log = {
    debug = "*console";
}

-- Virtual hosts
VirtualHost "localhost"
    ssl = {
        key = "/etc/prosody/certs/localhost.key";
        certificate = "/etc/prosody/certs/localhost.crt";
    }

VirtualHost "xmpp"
    ssl = {
        key = "/etc/prosody/certs/localhost.key";
        certificate = "/etc/prosody/certs/localhost.crt";
    }
    authentication = "internal_plain"
    allow_unencrypted_plain_auth = true

-- Multi-user chat rooms
Component "conference.localhost" "muc"
    name = "Conference Rooms"
    restrict_room_creation = false

Component "conference.xmpp" "muc"
    name = "Conference Rooms"
    restrict_room_creation = false

================
File: config/scripts/setup-repos.sh
================
#!/bin/sh
cd /home/projects || exit

echo "Starting repository setup..."

# Clone each repository
clone_repo() {
    repo=$1
    dirname=$(basename "$repo")
    if [ ! -d "$dirname" ]; then
        echo "Cloning $repo..."
        git clone "https://github.com/$repo" "$dirname"
        if [ -f "$dirname/package.json" ]; then
            cd "$dirname" || exit
            npm install
            cd .. || exit
        fi
    fi
}

# Process each repository
clone_repo "danja/hyperdata"
clone_repo "danja/semem"
clone_repo "danja/transmissions"
clone_repo "danja/tia"
clone_repo "danja/farelo"

# Install npm packages for subdirectories with package.json
find_and_install_npm() {
    dir=$1
    find "$dir" -name "package.json" -not -path "*/node_modules/*" | while read -r package_file; do
        package_dir=$(dirname "$package_file")
        echo "Installing npm packages in $package_dir..."
        cd "$package_dir" || continue
        npm install
        cd - > /dev/null || exit
    done
}

# Run npm install for all subdirectories with package.json files
find_and_install_npm "/home/projects"

# Set permissions
chown -R semem:semem /home/projects/*
echo "Repository setup complete"

================
File: fuseki/config.ttl
================
@prefix :     <http://localhost/fuseki/> .
@prefix f:    <http://jena.apache.org/fuseki#> .
@prefix rdf:  <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix tdb2: <http://jena.apache.org/2016/tdb#> .
@prefix ja:   <http://jena.hpl.hp.com/2005/11/Assembler#> .

[] rdf:type f:Server ;
   f:services (
     :ds
     :semem
     :test-db
     :test-mem
   ) .

:ds rdf:type f:Service ;
    f:name "ds" ;
    f:endpoint [ f:operation f:query ; ] ;
    f:endpoint [ f:operation f:update ; ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/ds" ;
    ] .

:semem rdf:type f:Service ;
    f:name "semem" ;
    f:endpoint [ f:operation f:query ; ] ;
    f:endpoint [ f:operation f:update ; ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/semem" ;
    ] .

:test-db rdf:type f:Service ;
    f:name "test-db" ;
    f:endpoint [ f:operation f:query ; ] ;
    f:endpoint [ f:operation f:update ; ] ;
    f:dataset [
        rdf:type tdb2:DatasetTDB2 ;
        tdb2:location "/fuseki/databases/test-db" ;
    ] .

:test-mem rdf:type f:Service ;
    f:name "test-mem" ;
    f:endpoint [ f:operation f:query ; ] ;
    f:endpoint [ f:operation f:update ; ] ;
    f:dataset [
        rdf:type ja:MemoryDataset ;
    ] .

================
File: fuseki/shiro.ini
================
#   Licensed to the Apache Software Foundation (ASF) under one or more
#   contributor license agreements.  See the NOTICE file distributed with
#   this work for additional information regarding copyright ownership.
#   The ASF licenses this file to You under the Apache License, Version 2.0
#   (the "License"); you may not use this file except in compliance with
#   the License.  You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.

[main]
# Development
ssl.enabled = false

plainMatcher=org.apache.shiro.authc.credential.SimpleCredentialsMatcher
#iniRealm=org.apache.shiro.realm.text.IniRealm
iniRealm.credentialsMatcher = $plainMatcher

#localhost=org.apache.jena.fuseki.authz.LocalhostFilter

[users]
# Implicitly adds "iniRealm =  org.apache.shiro.realm.text.IniRealm"
admin=admin123

[roles]

[urls]
## Control functions open to anyone
/$/status = anon
/$/ping   = anon

## and the rest are restricted
/$/** = authcBasic,user[admin]

## Sparql update is restricted
/*/update/** = authcBasic,user[admin]


## If you want simple, basic authentication user/password
## on the operations,
##    1 - set a password in [users]
##    2 - change the line above to:
## /$/** = authcBasic,user[admin]
## and set a better

## or to allow any access.
##/$/** = anon

# Everything else
/**=anon

================
File: jena-fuseki-docker-5.3.0/docker-compose.yaml
================
## Licensed under the terms of http://www.apache.org/licenses/LICENSE-2.0
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

version: '3.0'
services:
  fuseki:
    ## Example:
    ## command: [ "--tdb2", "--update", "--loc", "databases/DB2", "/ds" ]
    build:
      context: .
      dockerfile: Dockerfile
    image: fuseki
    ports:
      - "3030:3030"
    volumes:
      - ./logs:/fuseki/logs
      - ./databases:/fuseki/databases
#volumes:

================
File: jena-fuseki-docker-5.3.0/Dockerfile
================
## Licensed to the Apache Software Foundation (ASF) under one or more
## contributor license agreements.  See the NOTICE file distributed with
## this work for additional information regarding copyright ownership.
## The ASF licenses this file to You under the Apache License, Version 2.0
## (the "License"); you may not use this file except in compliance with
## the License.  You may obtain a copy of the License at
##
##     http://www.apache.org/licenses/LICENSE-2.0
##
## Unless required by applicable law or agreed to in writing, software
## distributed under the License is distributed on an "AS IS" BASIS,
## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
## See the License for the specific language governing permissions and
## limitations under the License.

## Apache Jena Fuseki server Dockerfile.

## This Dockefile builds a reduced footprint container.

ARG JAVA_VERSION=17

ARG ALPINE_VERSION=3.17.1
ARG JENA_VERSION=""

# Internal, passed between stages.
ARG FUSEKI_DIR=/fuseki
ARG FUSEKI_JAR=jena-fuseki-server-${JENA_VERSION}.jar
ARG JAVA_MINIMAL=/opt/java-minimal

## ---- Stage: Download and build java.
FROM eclipse-temurin:${JAVA_VERSION}-alpine AS base

ARG JAVA_MINIMAL
ARG JENA_VERSION
ARG FUSEKI_DIR
ARG FUSEKI_JAR
ARG REPO=https://repo1.maven.org/maven2
ARG JAR_URL=${REPO}/org/apache/jena/jena-fuseki-server/${JENA_VERSION}/${FUSEKI_JAR}

RUN [ "${JENA_VERSION}" != "" ] || { echo -e '\n**** Set JENA_VERSION ****\n' ; exit 1 ; }
RUN echo && echo "==== Docker build for Apache Jena Fuseki ${JENA_VERSION} ====" && echo

# Alpine: For objcopy used in jlink
RUN apk add --no-cache curl binutils

## -- Fuseki installed and runs in /fuseki.
WORKDIR $FUSEKI_DIR

## -- Download the jar file.
COPY download.sh .
RUN chmod a+x download.sh

# Download, with check of the SHA1 checksum.
RUN ./download.sh --chksum sha1 "$JAR_URL"

## -- Alternatives to download : copy already downloaded.
## COPY ${FUSEKI_JAR} .

## Use Docker ADD - does not retry, does not check checksum, and may run every build.
## ADD "$JAR_URL"

## -- Make reduced Java JDK

ARG JDEPS_EXTRA="jdk.crypto.cryptoki,jdk.crypto.ec"
RUN \
  JDEPS="$(jdeps --multi-release base --print-module-deps --ignore-missing-deps ${FUSEKI_JAR})"  && \
  jlink \
        --compress 2 --strip-debug --no-header-files --no-man-pages \
        --output "${JAVA_MINIMAL}" \
        --add-modules "${JDEPS},${JDEPS_EXTRA}"

ADD entrypoint.sh .
ADD log4j2.properties .

## ---- Stage: Build runtime
FROM alpine:${ALPINE_VERSION}

## Import ARGs
ARG JENA_VERSION
ARG JAVA_MINIMAL
ARG FUSEKI_DIR
ARG FUSEKI_JAR

# Install procps to fix TDB concurrent usage issues
# The ps command from procps is needed by Jena for TDB locking mechanism
RUN apk add --no-cache procps wget

COPY --from=base /opt/java-minimal /opt/java-minimal
COPY --from=base /fuseki /fuseki

WORKDIR $FUSEKI_DIR

ARG LOGS=${FUSEKI_DIR}/logs
ARG DATA=${FUSEKI_DIR}/databases

ARG JENA_USER=fuseki
ARG JENA_GROUP=$JENA_USER
ARG JENA_GID=1000
ARG JENA_UID=1000

# Run as this user
# -H : no home directory
# -D : no password
RUN addgroup -g "${JENA_GID}" "${JENA_GROUP}" && \
    adduser "${JENA_USER}" -G "${JENA_GROUP}" -s /bin/ash -u "${JENA_UID}" -H -D

RUN mkdir --parents "${FUSEKI_DIR}" && \
    chown -R $JENA_USER ${FUSEKI_DIR}

USER $JENA_USER

RUN \
    mkdir -p $LOGS && \
    mkdir -p $DATA && \
    chmod a+x entrypoint.sh

## Default environment variables.
ENV \
    JAVA_HOME=${JAVA_MINIMAL}           \
    JAVA_OPTIONS="-Xmx2048m -Xms2048m"  \
    JENA_VERSION=${JENA_VERSION}        \
    FUSEKI_JAR="${FUSEKI_JAR}"          \
    FUSEKI_DIR="${FUSEKI_DIR}"

EXPOSE 3030

ENTRYPOINT ["./entrypoint.sh" ]
CMD []

================
File: jena-fuseki-docker-5.3.0/download.sh
================
#!/bin/sh

## Licensed under the terms of http://www.apache.org/licenses/LICENSE-2.0
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This is an ash/dash script (it uses "local"), not a bash script.
# It can run in an Alpine image during a docker build.
#
# The advantage over using docker ADD is that it checks
# whether download file is already present and does not
# download each time.
#
# Shell script to download URL and check the checksum

USAGE="Usage: $(basename "$0") --chksum [sha1|sha512] URL"

if [ $# -eq 0 ]
then
    echo "$USAGE" 2>&1
    exit 1
fi

CHKSUM_TYPE='unset'

while [ $# -gt 0 ] ; do
    case "$1" in
    --chksum|-chksum|-sha|--sha)
        if [ $# -lt 2 ]
        then
        echo "$USAGE" 1>&2
        exit 1
        fi
        CHKSUM_TYPE=$2
        shift
        shift
        ;;
    -h|--help)
        echo "$USAGE" 1>&2
        exit 0
        ;;
    -*)
        echo "$USAGE" 1>&2
        exit 1
        ;;
    *)
        if [ $# -ne 1 ]
        then
        echo "$USAGE" 1>&2
        exit 1
        fi
        URL="$1"
        shift
        ;;
    esac
done

case "${CHKSUM_TYPE}" in
    unset)
    echo "$USAGE" 1>&2
    exit 1
    ;;
    sha*|md5) ;;
    *)
    echo "Bad checksum type: '$CHKSUM_TYPE' (must start 'sha' or be 'md5')" 2>&1
    exit 1
    ;;
esac

## ---- Script starts ----

ARTIFACT_URL="${URL}"
ARTIFACT_NAME="$(basename "$ARTIFACT_URL")"

# -------- Checksum details

CHKSUM_EXT=".${CHKSUM_TYPE}"
CHKSUM_URL="${ARTIFACT_URL}${CHKSUM_EXT}"
CHKSUM_FILE="${ARTIFACT_NAME}${CHKSUM_EXT}"
CHKSUMPROG="${CHKSUM_TYPE}sum"
# --------

CURL_FETCH_OPTS="-s -S --fail --location --max-redirs 3"
if false
then
    echo "ARTIFACT_URL=$ARTIFACT_URL"
    echo "CHKSUM_URL=$CHKSUM_URL"
fi

download() { # URL
    local URL="$1"
    local FN="$(basename "$URL")"
    if [ ! -e "$FN" ]
    then
    echo "Fetching $URL"
    curl $CURL_FETCH_OPTS "$URL" --output "$FN" \
        || { echo "Bad download of $FN" 2>&1 ; return 1 ; }
    else
    echo "$FN already present"
    fi
    return 0
}

checkChksum() { # Filename checksum
    local FN="$1"
    local CHKSUM="$2"
    if [ ! -e "$FN" ]
    then
    echo "No such file: '$FN'" 2>&1
    exit 1
    fi
    # NB Two spaces required for busybox
    echo "$CHKSUM  $FN" | ${CHKSUMPROG} -c > /dev/null
}

download "$ARTIFACT_URL" || exit 1

if [ -z "$CHKSUM" ]
then
    # Checksum not previously set.
    # Extract from file, copes with variations in content (filename or not)
    download "$CHKSUM_URL" || exit 1
    CHKSUM="$(cut -d' ' -f1 "$CHKSUM_FILE")"
fi

checkChksum "${ARTIFACT_NAME}" "$CHKSUM"
if [ $? = 0 ]
then
    echo "Good download: $ARTIFACT_NAME"
else
    echo "BAD download !!!! $ARTIFACT_NAME"
    echo "To retry: delete downloaded files and try again"
    exit 1
fi

================
File: jena-fuseki-docker-5.3.0/entrypoint.sh
================
#!/bin/sh
## Licensed under the terms of http://www.apache.org/licenses/LICENSE-2.0

# Clean up lock files if they exist
cleanup_locks() {
    echo "Checking for stale lock files..."
    LOCKS=$(find "${FUSEKI_DIR}/databases" -name "*.lock" 2>/dev/null || true)
    if [ -n "$LOCKS" ]; then
        echo "Found stale lock files, removing them:"
        echo "$LOCKS"
        find "${FUSEKI_DIR}/databases" -name "*.lock" -delete 2>/dev/null || true
    else
        echo "No stale lock files found"
    fi
}

# Function to clean up properly on exit/termination
cleanup() {
    echo "Shutting down Fuseki gracefully..."
    # Send SIGTERM to the Java process if it's running
    if [ -n "$PID" ] && kill -0 $PID 2>/dev/null; then
        kill -TERM $PID
        # Wait for the process to terminate
        wait $PID
    fi
    
    # Clean up lock files on exit
    cleanup_locks
    
    exit 0
}

# Trap signals
trap cleanup SIGINT SIGTERM

# Clean up any stale lock files before starting
cleanup_locks

# Start Fuseki
echo "Starting Fuseki with Java options: $JAVA_OPTIONS"
"$JAVA_HOME/bin/java" $JAVA_OPTIONS -jar "${FUSEKI_DIR}/${FUSEKI_JAR}" "$@" &
PID=$!

# Wait for the Java process
wait $PID

================
File: jena-fuseki-docker-5.3.0/LICENSE
================
Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

================
File: jena-fuseki-docker-5.3.0/log4j2.properties
================
## Licensed under the terms of http://www.apache.org/licenses/LICENSE-2.0
status = error
name = PropertiesConfig

## filters = threshold
## filter.threshold.type = ThresholdFilter
## filter.threshold.level = ALL

appender.console.type = Console
appender.console.name = OUT
appender.console.target = SYSTEM_OUT
appender.console.layout.type = PatternLayout
## appender.console.layout.pattern = %d{HH:mm:ss} %-5p %-15c{1} :: %m%n
## Include date.
appender.console.layout.pattern = [%d{yyyy-MM-dd HH:mm:ss}] %-5p %-15c{1} :: %m%n

## To a file.
## appender.file.type = File
## appender.file.name = FILE
## appender.file.fileName=/fuseki/logs/log.fuseki
## appender.file.layout.type=PatternLayout
## appender.file.layout.pattern = [%d{yyyy-MM-dd HH:mm:ss}] %-5p %-15c{1} :: %m%n

rootLogger.level                  = INFO
rootLogger.appenderRef.stdout.ref = OUT

logger.jena.name  = org.apache.jena
logger.jena.level = INFO

logger.arq-exec.name  = org.apache.jena.arq.exec
logger.arq-exec.level = INFO

logger.arq-info.name  = org.apache.jena.arq.info
logger.arq-info.level = INFO

logger.riot.name  = org.apache.jena.riot
logger.riot.level = INFO

logger.fuseki.name  = org.apache.jena.fuseki
logger.fuseki.level = INFO

logger.fuseki-fuseki.name  = org.apache.jena.fuseki.Fuseki
logger.fuseki-fuseki.level = INFO

logger.fuseki-server.name  = org.apache.jena.fuseki.Server
logger.fuseki-server.level = INFO

logger.fuseki-admin.name  = org.apache.jena.fuseki.Admin
logger.fuseki-admin.level = INFO

logger.jetty.name  = org.eclipse.jetty
logger.jetty.level = WARN

logger.shiro.name = org.apache.shiro
logger.shiro.level = WARN

# Hide issue with Shiro 1.5.0+, 2.0.0
logger.shiro-realm.name = org.apache.shiro.realm.text.IniRealm
logger.shiro-realm.level = ERROR

# This goes out in NCSA format
appender.plain.type = Console
appender.plain.name = PLAIN
appender.plain.layout.type = PatternLayout
appender.plain.layout.pattern = %m%n

logger.request-log.name                   = org.apache.jena.fuseki.Request
logger.request-log.additivity             = false
logger.request-log.level                  = OFF
logger.request-log.appenderRef.plain.ref  = PLAIN

================
File: jena-fuseki-docker-5.3.0/NOTICE
================
Apache Jena - module Fuseki (Docker)
Copyright 2011-2025 The Apache Software Foundation

This product includes software developed at
The Apache Software Foundation (http://www.apache.org/).

================
File: jena-fuseki-docker-5.3.0/README.md
================
# Apache Jena Fuseki Docker Tools

This package contains a Dockerfile, docker-compose file, and helper scripts to
create a docker container for Apache Jena Fuseki.

The docker container is based on 
[Fuseki main](https://jena.apache.org/documentation/fuseki2/fuseki-main)
for running a SPARQL server.

There is no UI - all configuration is by command line and all usage by via the
network protocols.

Databases can be mounted outside the docker container so they are preserved when
the container terminates.

This build system allows the user to customize the docker image.

The docker build downloads the server binary from 
[Maven central](https://repo1.maven.org/maven2/org/apache/jena/jena-fuseki-server/),
checking the download against the SHA1 checksum.

## Database

There is a volume mapping "./databases" in the current directory into the server.
This can be used to contain databases outside, but accessible to, the container
that do not get deleted when the container exits.

See examples below.

## Build

Choose the version number of Apache Jena release you wish to use. This toolkit
defaults to the version of the overall Jena release it was part of. It is best
to use the release of this set of tools from the same release of the desired
server.

    docker-compose build --build-arg JENA_VERSION=4.7.0

Note the build command must provide the version number.

## Test Run

`docker-compose run` can be used to test the build from the previous section.

Examples:

Start Fuseki with an in-memory, updatable dataset at http://<i>host</i>:3030/ds

    docker-compose run --rm --service-ports fuseki --mem /ds

Load a TDB2 database, and expose, read-only, via docker:

    mkdir -p databases/DB2
    tdb2.tdbloader --loc databases/DB2 MyData.ttl
    # Publish read-only
    docker-compose run --rm --name MyServer --service-ports fuseki --tdb2 --loc databases/DB2 /ds

To allow update on the database, add `--update`. Updates are persisted.

    docker-compose run --rm --name MyServer --service-ports fuseki --tdb2 --update --loc databases/DB2 /ds

See
[fuseki-configuration](https://jena.apache.org/documentation/fuseki2/fuseki-configuration.html)
for more information on command line arguments.

To use `docker-compose up`, edit the `docker-compose.yaml` to set the Fuseki
command line arguments appropriately.

## Layout

The default layout in the container is:

| Path  | Use | 
| ----- | --- |
| /opt/java-minimal | A reduced size Java runtime                      |
| /fuseki | The Fuseki installation                                    |
| /fuseki/log4j2.properties | Logging configuration                    |
| /fuseki/databases/ | Directory for a volume for persistent databases |

## Setting JVM arguments

Use `JAVA_OPTIONS`:

    docker-compose run --service-ports --rm -e JAVA_OPTIONS="-Xmx1048m -Xms1048m" --name MyServer fuseki --mem /ds

## Docker Commands

If you prefer to use `docker` directly:

Build:

    docker build --force-rm --build-arg JENA_VERSION=4.7.0 -t fuseki .

Run:

    docker run -i --rm -p "3030:3030" --name MyServer -t fuseki --mem /ds

With databases on a bind mount to host filesystem directory:

    MNT="--mount type=bind,src=$PWD/databases,dst=/fuseki/databases"
    docker run -i --rm -p "3030:3030" $MNT --name MyServer -t fuseki --tdb2 --update --loc databases/DB2 /ds

## Version specific notes:

* Versions of Jena up to 3.14.0 use Log4j1 for logging. The docker will build will ignore
   the log4j2.properties file
* Version 3.15.0: When run, a warning will be emitted.  
  `WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.`  
  This can be ignored.

================
File: monitor/Dockerfile
================
FROM node:alpine
WORKDIR /app
COPY package.json .
RUN npm install
COPY . .
EXPOSE 8080
CMD ["node", "index.js"]

================
File: monitor/index.js
================
import express from 'express';
import fetch from 'node-fetch';

const app = express();

const checkFusekiHealth = async () => {
    try {
        const response = await fetch('http://fuseki:3030/$/ping', {
            timeout: 5000
        });
        return {
            status: response.ok ? 'healthy' : 'unhealthy',
            responseTime: response.headers.get('X-Response-Time'),
            lastChecked: new Date().toISOString()
        };
    } catch (error) {
        return {
            status: 'unhealthy',
            error: error.message,
            lastChecked: new Date().toISOString()
        };
    }
};

const checkProsodyHealth = async () => {
    try {
        const response = await fetch('http://xmpp:5282/http-monitor', {
            timeout: 5000
        });
        return {
            status: response.ok ? 'healthy' : 'unhealthy',
            responseTime: response.headers.get('X-Response-Time'),
            lastChecked: new Date().toISOString()
        };
    } catch (error) {
        return {
            status: 'unhealthy',
            error: error.message,
            lastChecked: new Date().toISOString()
        };
    }
};

app.get('/health/fuseki', async (req, res) => {
    const health = await checkFusekiHealth();
    res.json(health);
});

app.get('/health/prosody', async (req, res) => {
    const health = await checkProsodyHealth();
    res.json(health);
});

app.get('/', async (req, res) => {
    const [fusekiHealth, prosodyHealth] = await Promise.all([
        checkFusekiHealth(),
        checkProsodyHealth()
    ]);

    res.send(`
    <h1>Service Health</h1>
    <h2>Fuseki</h2>
    <pre>${JSON.stringify(fusekiHealth, null, 2)}</pre>
    <h2>Prosody</h2>
    <pre>${JSON.stringify(prosodyHealth, null, 2)}</pre>
  `);
});

const port = process.env.PORT || 8080;
app.listen(port, '0.0.0.0', () => console.log(`Monitor service running on port ${port}`));

================
File: monitor/package.json
================
{
    "name": "tbox-monitor",
    "version": "1.0.0",
    "type": "module",
    "dependencies": {
        "express": "^4.21.2",
        "node-fetch": "^3.3.2"
    }
}

================
File: scripts/check_fuseki.sh
================
#!/bin/bash
# Enhanced script to check if Fuseki is running correctly

set -e

# Check if container is running
echo "Checking if Fuseki container is running..."
FUSEKI_CONTAINER=$(docker ps -q -f name=tbox_fuseki)

if [ -z "$FUSEKI_CONTAINER" ]; then
    echo "ERROR: Fuseki container is not running!"
    echo "Starting the tbox service..."
    sudo systemctl restart tbox.service
    sleep 5
    FUSEKI_CONTAINER=$(docker ps -q -f name=tbox_fuseki)
    if [ -z "$FUSEKI_CONTAINER" ]; then
        echo "ERROR: Failed to start Fuseki container!"
        exit 1
    fi
    echo "Fuseki container started successfully."
fi

echo "Waiting for Fuseki to be ready..."
until curl -s http://localhost:4030/$/ping > /dev/null; do
    echo "Waiting for Fuseki..."
    sleep 2
done
echo "Fuseki is up!"

# Check datasets
echo "Checking datasets..."
curl -X GET http://localhost:4030/$/datasets \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" && echo -e "\nDataset check - It works!"

echo -e "\nAdding test data..."
curl -X POST http://localhost:4030/ds \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-update" \
  --data "INSERT DATA { <http://example/s> <http://example/p> <http://example/o> }" && echo "Insert - It works!"

echo -e "\nQuerying data (SELECT)..."
curl -X POST http://localhost:4030/ds \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: application/sparql-results+json" \
  --data "SELECT * WHERE { ?s ?p ?o }" && echo "Select - It works!"

echo -e "\nQuerying data (CONSTRUCT)..."
curl -X POST http://localhost:4030/ds \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-query" \
  -H "Accept: text/turtle" \
  --data "CONSTRUCT { ?s ?p ?o } WHERE { ?s ?p ?o }" && echo "Construct - It works!"

echo -e "\nChecking for TDB lock files..."
docker exec $FUSEKI_CONTAINER find /fuseki/databases -name "*.lock" | sort

echo -e "\nAll tests passed! Fuseki is working correctly."

================
File: scripts/clean-fuseki-locks.sh
================
#!/bin/bash
# Script to clean up Fuseki lock files and restart the service

set -e

echo "Stopping tbox service..."
sudo systemctl stop tbox.service || true

echo "Making sure all Docker containers are stopped..."
docker compose down || true

echo "Removing all Fuseki lock files..."
sudo find ./data/fuseki -name "*.lock" -type f -delete || true

echo "Setting proper permissions on data directory..."
sudo chown -R $(id -u):$(id -g) ./data/fuseki

echo "Rebuilding the Fuseki container..."
docker compose build fuseki

echo "Starting tbox service..."
sudo systemctl start tbox.service

echo "Waiting for Fuseki to start..."
sleep 10

echo "Checking Fuseki container status..."
docker ps | grep fuseki

================
File: scripts/del2.sh
================
echo -e "\nDeleting data from ..."
curl -X POST http://localhost:4030/semem/update \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-update" \
  -H "Accept: application/sparql-results+json" \
  --data "DELETE { ?s ?p ?o} WHERE { ?s ?p ?o }"

================
File: scripts/delete-triples.sh
================
echo -e "\nDeleting data from ..."
curl -X POST http://localhost:4030/test-mem/update \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-update" \
  -H "Accept: application/sparql-results+json" \
  --data "DELETE { ?s ?p ?o} WHERE { ?s ?p ?o }"

================
File: scripts/rebuild-restart.sh
================
# docker-compose down --volumes  # Remove containers and volumes

docker-compose down
docker-compose build --no-cache  # Rebuild without cache
docker-compose up -d  # Start fresh

docker-compose logs

curl -X GET http://localhost:4030/test/query \
  -H "Accept: application/sparql-results+json" \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  --data-urlencode "query=SELECT * WHERE { ?s ?p ?o }"

================
File: scripts/restart-fuseki.sh
================
#!/bin/bash
# Script to safely restart Fuseki

set -e

echo "Stopping tbox service..."
sudo systemctl stop tbox.service

echo "Checking for any running containers..."
FUSEKI_CONTAINER=$(docker ps -q -f name=tbox_fuseki)

if [ ! -z "$FUSEKI_CONTAINER" ]; then
    echo "Stopping Fuseki container..."
    docker stop $FUSEKI_CONTAINER
    
    echo "Removing Fuseki container..."
    docker rm $FUSEKI_CONTAINER
fi

echo "Rebuilding Fuseki container..."
cd /home/danny/hyperdata/tbox
docker compose build fuseki

echo "Starting tbox service..."
sudo systemctl start tbox.service

echo "Checking Fuseki status..."
sleep 5
docker logs $(docker ps -q -f name=tbox_fuseki)

echo "Fuseki restart completed successfully!"

================
File: scripts/ssh-entry.sh
================
#!/bin/sh

# starts openssh (in the container)
/usr/sbin/sshd -D &
tail -f /dev/null

================
File: scripts/tbox.service
================
[Unit]
Description=TBox Docker Environment
Requires=docker.service
After=docker.service

[Service]
Type=oneshot
RemainAfterExit=yes
WorkingDirectory=/home/danny/hyperdata/tbox
ExecStart=/usr/bin/docker compose up -d
ExecStop=/usr/bin/docker compose down
TimeoutStartSec=0

[Install]
WantedBy=multi-user.target

================
File: scripts/test_fuseki-persistence.sh
================
#!/bin/bash

echo "Waiting for Fuseki to be ready..."
until curl -s http://localhost:4030/$/ping > /dev/null; do
    echo "Waiting for Fuseki..."
    sleep 2
done
echo "Fuseki is up!"

echo "Adding test data..."
curl -X POST http://localhost:4030/ds/update \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  -H "Content-Type: application/sparql-update" \
  --data "INSERT DATA { <http://example/s> <http://example/p> <http://example/o> }"

echo -e "\nRestarting containers..."
docker-compose restart

echo "Waiting for Fuseki to be ready again..."
until curl -s http://localhost:4030/$/ping > /dev/null; do
    echo "Waiting for Fuseki..."
    sleep 2
done

echo -e "\nQuerying data..."
curl -X GET http://localhost:4030/ds/query \
  -H "Accept: application/sparql-results+json" \
  --data-urlencode "query=SELECT * WHERE { ?s ?p ?o }"

================
File: services/app/src/app.js
================
const express = require('express');
const app = express();
const port = 8311;

app.get('/', (req, res) => {
    const headers = JSON.stringify(req.headers, null, 2);
    res.send(`
        <pre>Request Headers:
        ${headers}</pre>
        <hr>
        Hello, Sandboxed World!
    `);
});

app.get('/health', (req, res) => {
    res.json({
        status: 'ok',
        time: new Date(),
        uptime: process.uptime()
    });
});

app.listen(port, '0.0.0.0', () => console.log(`Server running on port ${port}`));

================
File: services/app/Dockerfile
================
FROM node:alpine
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY src ./src
EXPOSE 8311
CMD ["node", "src/app.js"]

================
File: services/app/package.json
================
{
    "name": "tbox-app",
    "version": "1.0.0",
    "description": "TBox Application Service",
    "main": "src/app.js",
    "dependencies": {
        "express": "^4.21.2"
    },
    "scripts": {
        "start": "node src/app.js"
    }
}

================
File: services/monitor/src/index.js
================
import express from 'express';
import fetch from 'node-fetch';

const app = express();

const checkFusekiHealth = async () => {
    try {
        const response = await fetch('http://fuseki:3030/$/ping', {
            timeout: 5000
        });
        return {
            status: response.ok ? 'healthy' : 'unhealthy',
            responseTime: response.headers.get('X-Response-Time'),
            lastChecked: new Date().toISOString()
        };
    } catch (error) {
        return {
            status: 'unhealthy',
            error: error.message,
            lastChecked: new Date().toISOString()
        };
    }
};

const checkProsodyHealth = async () => {
    try {
        const response = await fetch('http://xmpp:5282/http-monitor', {
            timeout: 5000
        });
        return {
            status: response.ok ? 'healthy' : 'unhealthy',
            responseTime: response.headers.get('X-Response-Time'),
            lastChecked: new Date().toISOString()
        };
    } catch (error) {
        return {
            status: 'unhealthy',
            error: error.message,
            lastChecked: new Date().toISOString()
        };
    }
};

// General health endpoint
app.get('/health', async (req, res) => {
    const health = {
        status: 'healthy',
        timestamp: new Date().toISOString(),
        services: {}
    };

    try {
        health.services.fuseki = await checkFusekiHealth();
        health.services.prosody = await checkProsodyHealth();

        // If any service is unhealthy, mark overall status as unhealthy
        if (Object.values(health.services).some(service => service.status === 'unhealthy')) {
            health.status = 'unhealthy';
        }

        res.json(health);
    } catch (error) {
        health.status = 'unhealthy';
        health.error = error.message;
        res.status(500).json(health);
    }
});

app.get('/health/fuseki', async (req, res) => {
    const health = await checkFusekiHealth();
    res.json(health);
});

app.get('/health/prosody', async (req, res) => {
    const health = await checkProsodyHealth();
    res.json(health);
});

app.get('/', async (req, res) => {
    const [fusekiHealth, prosodyHealth] = await Promise.all([
        checkFusekiHealth(),
        checkProsodyHealth()
    ]);

    res.send(`
    <h1>Service Health</h1>
    <h2>Fuseki</h2>
    <pre>${JSON.stringify(fusekiHealth, null, 2)}</pre>
    <h2>Prosody</h2>
    <pre>${JSON.stringify(prosodyHealth, null, 2)}</pre>
  `);
});

const port = process.env.PORT || 8080;
app.listen(port, '0.0.0.0', () => console.log(`Monitor service running on port ${port}`));

================
File: services/monitor/src/index.js.backup
================
import express from 'express';
import fetch from 'node-fetch';

const app = express();

const checkFusekiHealth = async () => {
    try {
        const response = await fetch('http://fuseki:3030/$/ping', {
            timeout: 5000
        });
        return {
            status: response.ok ? 'healthy' : 'unhealthy',
            responseTime: response.headers.get('X-Response-Time'),
            lastChecked: new Date().toISOString()
        };
    } catch (error) {
        return {
            status: 'unhealthy',
            error: error.message,
            lastChecked: new Date().toISOString()
        };
    }
};

const checkProsodyHealth = async () => {
    try {
        const response = await fetch('http://xmpp:5282/http-monitor', {
            timeout: 5000
        });
        return {
            status: response.ok ? 'healthy' : 'unhealthy',
            responseTime: response.headers.get('X-Response-Time'),
            lastChecked: new Date().toISOString()
        };
    } catch (error) {
        return {
            status: 'unhealthy',
            error: error.message,
            lastChecked: new Date().toISOString()
        };
    }
};

app.get('/health/fuseki', async (req, res) => {
    const health = await checkFusekiHealth();
    res.json(health);
});

app.get('/health/prosody', async (req, res) => {
    const health = await checkProsodyHealth();
    res.json(health);
});

app.get('/', async (req, res) => {
    const [fusekiHealth, prosodyHealth] = await Promise.all([
        checkFusekiHealth(),
        checkProsodyHealth()
    ]);

    res.send(`
    <h1>Service Health</h1>
    <h2>Fuseki</h2>
    <pre>${JSON.stringify(fusekiHealth, null, 2)}</pre>
    <h2>Prosody</h2>
    <pre>${JSON.stringify(prosodyHealth, null, 2)}</pre>
  `);
});

const port = process.env.PORT || 8080;
app.listen(port, '0.0.0.0', () => console.log(`Monitor service running on port ${port}`));

================
File: services/monitor/Dockerfile
================
FROM node:alpine
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY src ./src
EXPOSE 8080
CMD ["node", "src/index.js"]

================
File: services/monitor/package.json
================
{
    "name": "tbox-monitor",
    "version": "1.0.0",
    "type": "module",
    "dependencies": {
        "express": "^4.21.2",
        "node-fetch": "^3.3.2"
    }
}

================
File: services/web/public/index.html
================
<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TBox Dashboard</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 2em;
        }

        .status-card {
            border: 1px solid #ddd;
            padding: 1em;
            margin: 1em 0;
        }

        .healthy {
            color: green;
        }

        .unhealthy {
            color: red;
        }
    </style>
</head>

<body>
    <h1>TBox System Status</h1>
    <div class="status-card">
        <h2>Service Health</h2>
        <p>Monitor: <span id="monitor-status">Checking...</span></p>
        <p>Fuseki: <span id="fuseki-status">Checking...</span></p>
        <p>XMPP: <span id="xmpp-status">Checking...</span></p>
    </div>
    <script>
        async function updateStatus() {
            try {
                const response = await fetch('/health');
                const data = await response.json();
                document.getElementById('monitor-status').textContent = data.status;
                document.getElementById('monitor-status').className = data.status;
            } catch (error) {
                console.error('Error fetching status:', error);
            }
        }
        updateStatus();
        setInterval(updateStatus, 30000);
    </script>
</body>

</html>

================
File: .gitignore
================
# Ignore everything in projects except .gitkeep
projects/*
!projects/.gitkeep

fuseki-data
fuseki/databases
fuseki/storees
data
data/fuseki
data/fuseki/semem
data/fuseki/ds
data/fuseki/test-db

# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
lerna-debug.log*
.pnpm-debug.log*

# Diagnostic reports (https://nodejs.org/api/report.html)
report.[0-9]*.[0-9]*.[0-9]*.[0-9]*.json

# Runtime data
pids
*.pid
*.seed
*.pid.lock

# Directory for instrumented libs generated by jscoverage/JSCover
lib-cov

# Coverage directory used by tools like istanbul
coverage
*.lcov

# nyc test coverage
.nyc_output

# Grunt intermediate storage (https://gruntjs.com/creating-plugins#storing-task-files)
.grunt

# Bower dependency directory (https://bower.io/)
bower_components

# node-waf configuration
.lock-wscript

# Compiled binary addons (https://nodejs.org/api/addons.html)
build/Release

# Dependency directories
node_modules/
jspm_packages/

# Snowpack dependency directory (https://snowpack.dev/)
web_modules/

# TypeScript cache
*.tsbuildinfo

# Optional npm cache directory
.npm

# Optional eslint cache
.eslintcache

# Optional stylelint cache
.stylelintcache

# Microbundle cache
.rpt2_cache/
.rts2_cache_cjs/
.rts2_cache_es/
.rts2_cache_umd/

# Optional REPL history
.node_repl_history

# Output of 'npm pack'
*.tgz

# Yarn Integrity file
.yarn-integrity

# dotenv environment variable files
.env
.env.development.local
.env.test.local
.env.production.local
.env.local

# parcel-bundler cache (https://parceljs.org/)
.cache
.parcel-cache

# Next.js build output
.next
out

# Nuxt.js build / generate output
.nuxt
dist

# Gatsby files
.cache/
# Comment in the public line in if your project uses Gatsby and not Next.js
# https://nextjs.org/blog/next-9-1#public-directory-support
# public

# vuepress build output
.vuepress/dist

# vuepress v2.x temp and cache directory
.temp
.cache

# Docusaurus cache and generated files
.docusaurus

# Serverless directories
.serverless/

# FuseBox cache
.fusebox/

# DynamoDB Local files
.dynamodb/

# TernJS port file
.tern-port

# Stores VSCode versions used for testing VSCode extensions
.vscode-test

# yarn v2
.yarn/cache
.yarn/unplugged
.yarn/build-state.yml
.yarn/install-state.gz
.pnp.*

================
File: about.md
================
Issue with the Fuseki image

https://github.com/stain/jena-docker/issues/34
/etc/systemd/system/tbox.service

need to integrate :
https://jena.apache.org/documentation/fuseki2/fuseki-docker.html
see `jena-fuseki-docker-5.3.0`

workaround for now:

```sh
sudo systemctl stop tbox
cd ~/hyperdata/tbox # my local dir
docker-compose down
docker-compose up -d
```

---

cd ~/hyperdata/tbox

http://localhost:4040/ - status monitor

sudo systemctl stop fuseki
sudo systemctl disable fuseki

docker-compose logs

sudo systemctl start tbox
cd ~/hyperdata/tbox # my local dir

docker-compose build --no-cache
docker-compose up -d

check http://localhost:4030/
should be Fuseki
Username: admin
Password: admin123

```
cd ~/hyperdata/tbox # my local dir
docker-compose up -d
docker-compose logs -f
```

```sh
sudo systemctl stop tbox
cd ~/hyperdata/tbox # my local dir
docker-compose down
```

```sh
#docker-compose build --no-cache
#sudo systemctl start tbox.service
```

docs/howtos/tbox-autostart_2025-01-26.md

```sh
curl -X POST http://localhost:4030/hyperdata/query   -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)"   -H "Content-Type: application/sparql-query"   -H "Accept: application/sparql-results+json"   --data "SELECT * WHERE { ?s ?p ?o } LIMIT 1"
```

```sh
cd ~/hyperdata/tbox # my local dir
docker-compose up -d
```

```sh
ssh semem@localhost -p 2222
...
exit
```

```sh
cd ~/hyperdata/tbox # my local dir
docker-compose down
docker-compose build --no-cache
rm logs/startup.log
docker-compose up -d
docker-compose logs -f > logs/startup.log
```

```sh
ssh root@localhost -p 2222
```

check syntax :

```sh
cd ~/hyperdata/tbox/config/fuseki
rapper -c -i turtle config.ttl
```

docker run -d -p 2222:22 your-image-name

---

`docs/artifacts_2025-01-19`

docker-compose build --no-cache
docker-compose up -d

# Make setup script executable

chmod +x projects/setup-repos.sh

# Build and start containers

docker-compose up --build -d

# Check logs

docker-compose logs -f

docker-compose down

---

next steps are in

/home/danny/github-danny/hyperdata/packages/tbox/docs/artifacts_2024-12-28

docker-compose restart monitor will restart just the monitor service with updated index.js.
For a complete rebuild: docker-compose up -d --build monitor

Here are the key commands to rebuild from scratch:

Stop and remove all containers/volumes:

bashCopydocker-compose down --volumes

Rebuild without using cache:

bashCopydocker-compose build --no-cache

Start everything up:

docker-compose up -d

Check logs for issues:

docker-compose logs
These commands are actually stored in restart.sh in your project.
The monitor dashboard will be available at http://localhost:4040 once everything is up.

Restart:
http://localhost:4000/
http://localhost:4030/ - Fuseki
http://localhost:4080/

```sh
 docker-compose up --build

docker-compose down --volumes  # Remove containers and volumes
docker-compose build --no-cache  # Rebuild without cache
docker-compose up -d  # Start fresh

docker-compose logs

curl -X GET http://localhost:4030/ds/query \
  -H "Accept: application/sparql-results+json" \
  --data-urlencode "query=SELECT * WHERE { ?s ?p ?o }"

curl -X GET http://localhost:4030/test/query \
  -H "Accept: application/sparql-results+json" \
  -H "Authorization: Basic $(echo -n 'admin:admin123' | base64)" \
  --data-urlencode "query=SELECT * WHERE { ?s ?p ?o }"
```

Access monitor dashboard at http://localhost:4040

================
File: config.ttl
================
@prefix fuseki:  <http://jena.apache.org/fuseki#> .
@prefix rdf:     <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix tdb2:    <http://jena.apache.org/2016/tdb#> .

[] rdf:type fuseki:Server ;
   fuseki:services (
     [ rdf:type fuseki:Service ;
       fuseki:name "ds" ;
       fuseki:endpoint [ fuseki:operation fuseki:query ; ] ;
       fuseki:endpoint [ fuseki:operation fuseki:update ; ] ;
       fuseki:dataset [ rdf:type tdb2:DatasetTDB2 ;
                       tdb2:location "/fuseki/databases/ds" ;
                     ] ;
     ]) .

================
File: docker-compose.override.yml
================
version: "3"
services:
  ssh-server:
    environment:
      - ENABLE_SSH_PASSWORD=true
    command: >
      sh -c '
        echo "Configuring SSH server..."
        echo "PermitRootLogin yes" >> /etc/ssh/sshd_config
        echo "PasswordAuthentication yes" >> /etc/ssh/sshd_config
        echo "Running repository setup..."
        /usr/local/bin/setup-repos.sh
        echo "Starting SSH daemon..."
        /usr/sbin/sshd -D -e
      '
      
  fuseki:
    build:
      context: ./jena-fuseki-docker-5.3.0
      args:
        - JENA_VERSION=5.3.0
    platform: linux/amd64
    user: "${UID:-1000}:${GID:-1000}"
    volumes:
      - ./data/fuseki:/fuseki/databases
      - ./config/fuseki:/fuseki/configuration
    environment:
      - ADMIN_PASSWORD=admin123
      - FUSEKI_CONFIG_FILE=/fuseki/configuration/config.ttl
      - FUSEKI_BASE=/fuseki
      - SHIRO_INI=/fuseki/configuration/shiro.ini
      - JVM_ARGS=-Xmx2g
    # Add init system to properly handle process termination
    init: true
    # This will ensure the container restarts if there are issues
    restart: unless-stopped
    # Healthcheck to verify Fuseki is running properly
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3030/"]
      interval: 1m
      timeout: 10s
      retries: 3

================
File: docker-compose.yml
================
version: "3"
services:
  ssh-server:
    build: .
    ports:
      - "2222:22"
    volumes:
      - ./projects:/home/projects
      - ./config/scripts:/scripts:ro
      - node_modules:/home/projects/node_modules
      - npm_cache:/root/.npm
      - ssh_config:/root/.ssh
    environment:
      - NODE_ENV=production
      - NODE_TLS_REJECT_UNAUTHORIZED=0
    healthcheck:
      test: ["CMD", "pgrep", "sshd"]
      interval: 30s
      timeout: 10s
      retries: 3

  app:
    build:
      context: ./services/app
    ports:
      - "4000:8311"
    depends_on:
      - fuseki
    environment:
      - FUSEKI_URL=http://fuseki:3030
      - FUSEKI_DATASET=semem

  fuseki:
    image: stain/jena-fuseki
    ports:
      - "4030:3030"
    volumes:
      - ./data/fuseki:/fuseki/databases
      - ./config/fuseki:/fuseki/configuration
    environment:
      - ADMIN_PASSWORD=admin123
      - FUSEKI_CONFIG_FILE=/fuseki/configuration/config.ttl
      - FUSEKI_BASE=/fuseki
      - SHIRO_INI=/fuseki/configuration/shiro.ini
      - JVM_ARGS=-Xmx2g

  nginx:
    image: nginx:alpine
    ports:
      - "4080:4080"
    volumes:
      - ./config/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./services/web/public:/usr/share/nginx/html:ro
    depends_on:
      - app
      - fuseki

  xmpp:
    image: prosody/prosody
    ports:
      - "5222:5222"
      - "5269:5269"
      - "5280:5280"
    volumes:
      - ./config/prosody/prosody.cfg.lua:/etc/prosody/prosody.cfg.lua:ro
      - ./config/certs:/etc/prosody/certs:ro
    environment:
      - PROSODY_ADMIN_JID=admin@localhost
      - PROSODY_ADMIN_PASSWORD=admin123
      - NODE_TLS_REJECT_UNAUTHORIZED=0
    restart: unless-stopped

  monitor:
    build:
      context: ./services/monitor
    ports:
      - "4040:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - app
      - fuseki
      - xmpp

volumes:
  node_modules:
  npm_cache:
  ssh_config:
  data:
    driver: local

================
File: Dockerfile
================
FROM alpine:latest

RUN apk add --update --no-cache \
    nodejs \
    npm \
    nginx \
    openssh \
    bash \
    curl \
    wget \
    git \
    && rm -rf /var/cache/apk/*

# SSH Configuration
RUN mkdir -p /var/run/sshd && \
    ssh-keygen -A && \
    sed -i 's/#PermitRootLogin.*/PermitRootLogin yes/' /etc/ssh/sshd_config && \
    sed -i 's/#PasswordAuthentication.*/PasswordAuthentication yes/' /etc/ssh/sshd_config && \
    sed -i 's/PasswordAuthentication no/PasswordAuthentication yes/' /etc/ssh/sshd_config && \
    echo "PermitRootLogin yes" >> /etc/ssh/sshd_config && \
    echo "PasswordAuthentication yes" >> /etc/ssh/sshd_config

# User Setup
RUN adduser -D -s /bin/bash semem && \
    echo "semem:semem" | chpasswd && \
    echo "root:semem" | chpasswd

# Directory Setup
RUN mkdir -p /home/projects && \
    chown -R semem:semem /home/projects && \
    chmod 755 /home/projects

COPY config/scripts/setup-repos.sh /usr/local/bin/
# COPY projects/setup-repos.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/setup-repos.sh

# Create startup script
RUN echo '#!/bin/sh' > /start.sh && \
    echo 'echo "Configuring SSH for password auth..."' >> /start.sh && \
    echo 'sed -i "s/#PermitRootLogin.*/PermitRootLogin yes/" /etc/ssh/sshd_config' >> /start.sh && \
    echo 'sed -i "s/#PasswordAuthentication.*/PasswordAuthentication yes/" /etc/ssh/sshd_config' >> /start.sh && \
    echo 'sed -i "s/PasswordAuthentication no/PasswordAuthentication yes/" /etc/ssh/sshd_config' >> /start.sh && \
    echo 'echo "PermitRootLogin yes" >> /etc/ssh/sshd_config' >> /start.sh && \
    echo 'echo "PasswordAuthentication yes" >> /etc/ssh/sshd_config' >> /start.sh && \
    echo 'echo "Running repository setup..."' >> /start.sh && \
    echo '/usr/local/bin/setup-repos.sh' >> /start.sh && \
    echo 'echo "Starting SSH daemon..."' >> /start.sh && \
    echo '/usr/sbin/sshd -D -e' >> /start.sh && \
    chmod +x /start.sh

EXPOSE 22 3770 8311
ENTRYPOINT ["/start.sh"]

================
File: Dockerfile copy
================
FROM alpine:latest

# Install essential packages
RUN apk add --update --no-cache \
    nodejs \
    npm \
    nginx \
    openssh-server \
    bash \
    curl \
    wget \
    git \
    && rm -rf /var/cache/apk/*

# SSH Configuration
RUN ssh-keygen -A
RUN mkdir -p /var/run/sshd

# User Setup
RUN addgroup -S semem && \
    adduser -S -G semem -s /bin/bash semem && \
    echo "semem:semem" | chpasswd && \
    echo "root:semem" | chpasswd

# SSH Security Configuration
RUN sed -i 's/PermitRootLogin prohibit-password/PermitRootLogin yes/' /etc/ssh/sshd_config && \
    sed -i 's/#PasswordAuthentication yes/PasswordAuthentication yes/' /etc/ssh/sshd_config

# Projects Directory Setup
RUN mkdir -p /home/projects && \
    chown -R semem:semem /home/projects && \
    chmod 755 /home/projects

# Add projects to semem's PATH
RUN echo "export PATH=$PATH:/home/projects/node_modules/.bin" >> /home/semem/.profile

# Copy and Configure Setup Script
COPY projects/setup-repos.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/setup-repos.sh && \
    chown semem:semem /usr/local/bin/setup-repos.sh

# Nginx Configuration
COPY nginx.conf /etc/nginx/nginx.conf

# Set working directory
WORKDIR /home/projects

# Create startup script
RUN echo '#!/bin/sh' > /start.sh && \
    echo '/usr/local/bin/setup-repos.sh' >> /start.sh && \
    echo '/usr/sbin/sshd -D' >> /start.sh && \
    chmod +x /start.sh

# Create non-root user directories
RUN mkdir -p /home/semem/app /home/semem/data && \
    chown -R semem:semem /home/semem

# Expose ports
EXPOSE 22 3770 8311

# Set entrypoint
ENTRYPOINT ["/start.sh"]

================
File: Dockerfile.prosody
================
FROM prosody/prosody

USER root
RUN mkdir -p /var/lib/prosody/logs && \
    touch /var/lib/prosody/logs/prosody.log /var/lib/prosody/logs/error.log && \
    chown -R prosody:prosody /var/lib/prosody

USER prosody

================
File: ecosystem.config.js
================
module.exports = {
    apps: [
        {
            name: 'app',
            script: './projects/app/src/app.js',
            instances: 1,
            autorestart: true,
            watch: false,
            env: {
                NODE_ENV: 'production',
                PORT: 8311
            }
        },
        {
            name: 'monitor',
            script: './projects/monitor/src/index.js',
            instances: 1,
            autorestart: true,
            watch: false,
            env: {
                NODE_ENV: 'production',
                PORT: 8080
            }
        }
    ]
}

================
File: fuseki-service-old
================
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# =========
#
# Fuseki service configuration / unit file for systemd
#
# Usage:
# ------
#
# 1. Place this file under /etc/systemd/system/
# 2. Create a system user called "fuseki" and make sure it has permission
#    to access the Fuseki configuration and databases
# 3. Adjust the paths and other settings below if necessary
# 4. Activate using: sudo systemctl enable fuseki.service

[Unit]
Description=Fuseki

[Service]
# Edit environment variables to match your installation
Environment=FUSEKI_HOME=/opt/fuseki
Environment=FUSEKI_BASE=/etc/fuseki
# Edit the line below to adjust the amount of memory allocated to Fuseki
Environment=JVM_ARGS=-Xmx4G
# Edit to match your installation
ExecStart=/opt/fuseki/fuseki-server
# Run as user "fuseki"
User=root
Restart=on-abort
# Java processes exit with status 143 when terminated by SIGTERM, this
# should be considered a successful shutdown
SuccessExitStatus=143
### By default, the service logs to journalctl only.
### If additional logging to a file is required, uncomment the following three lines
# StandardOutput=syslog
# StandardError=syslog
# SyslogIdentifier=fuseki
### This logs to syslog. If, e.g., rsyslogd is used, you can provide a file
### /etc/rsyslog.d/fuseki.conf, consisting of the following two lines (uncommented)
### if $programname == 'fuseki' then /var/log/fuseki/stderrout.log
### if $programname == 'fuseki' then stop


[Install]
WantedBy=multi-user.target

================
File: fuseki.service
================
[Unit]
Description=Apache Jena Fuseki Docker Container
Requires=docker.service
After=docker.service

[Service]
Type=simple
WorkingDirectory=/home/danny/hyperdata/tbox
ExecStartPre=/usr/bin/docker compose build fuseki
ExecStart=/usr/bin/docker compose up fuseki
ExecStop=/usr/bin/docker compose stop fuseki
Restart=always
RestartSec=10s

[Install]
WantedBy=multi-user.target

================
File: LICENSE
================
MIT License

Copyright (c) 2024 Danny Ayers

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: nginx.conf
================
events {
    worker_connections 1024;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    upstream app_server {
        server app:8311;
    }

    upstream fuseki_server {
        server fuseki:3030;
    }

    server {
        listen 4080;
        root /usr/share/nginx/html;
        index index.html;

        # CORS configuration
        add_header 'Access-Control-Allow-Origin' '*';
        add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, PUT, DELETE';
        add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';

        location / {
            try_files $uri $uri/ /index.html;
        }

        location /api/ {
            if ($request_method = 'OPTIONS') {
                add_header 'Access-Control-Allow-Origin' '*';
                add_header 'Access-Control-Allow-Methods' 'GET, POST, OPTIONS, PUT, DELETE';
                add_header 'Access-Control-Allow-Headers' 'DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';
                add_header 'Access-Control-Max-Age' 1728000;
                add_header 'Content-Type' 'text/plain charset=UTF-8';
                add_header 'Content-Length' 0;
                return 204;
            }

            proxy_pass http://app_server;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_cache_bypass $http_upgrade;
        }

        location /fuseki/ {
            proxy_pass http://fuseki_server/;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        }
    }
}

================
File: package-ref.json
================
{
    "name": "semem",
    "version": "1.0.0",
    "description": "Semantic Memory",
    "type": "module",
    "main": "index.js",
    "engines": {
        "node": ">=20.11.0"
    },
    "scripts": {
        "test": "jasmine --config=jasmine.json --reporter=tests/helpers/reporter.js",
        "cov": "nyc -a --include=src --reporter=lcov npm run test",
        "docs": "jsdoc -c jsdoc.json",
        "rp": "repomix -c repomix.config.json . "
    },
    "repository": {
        "type": "git",
        "url": "git+https://github.com/danja/semem.git"
    },
    "keywords": [
        "semantic",
        "memory",
        "llm",
        "rdf",
        "sparql"
    ],
    "author": "Danny Ayers",
    "license": "MIT",
    "bugs": {
        "url": "https://github.com/danja/semem/issues"
    },
    "homepage": "https://github.com/danja/semem#readme",
    "devDependencies": {
        "jasmine": "^5.5.0",
        "jasmine-spec-reporter": "^7.0.0",
        "jsdoc": "^4.0.4"
    },
    "dependencies": {
        "@langchain/core": "^0.3.19",
        "@langchain/openai": "^0.3.14",
        "faiss-node": "^0.5.1",
        "graphology": "^0.25.4",
        "ml-kmeans": "^6.0.0",
        "ollama": "^0.5.10"
    }
}

================
File: package.json
================
{
  "name": "tbox",
  "version": "1.0.0",
  "description": "Docker-contained environment for hyperdata.it apps",
  "private": true,
  "workspaces": [
    "services/*"
  ],
  "scripts": {
    "start": "docker-compose up",
    "build": "docker-compose build",
    "test": "npm run test --workspaces",
    "lint": "npm run lint --workspaces",
    "clean": "docker-compose down --volumes",
    "rp": "repomix -c repomix.config.json ."
  },
  "keywords": [
    "docker",
    "fuseki",
    "prosody",
    "nginx"
  ],
  "author": "Danny Ayers",
  "license": "MIT"
}

================
File: README.md
================
# tbox

a minimal Docker-contained environment, primarily for Transmissions

================
File: rebuild-start.sh
================
#!/bin/bash

# cd ~/hyperdata/tbox # my local dir

docker-compose down
chmod -R 777 ./data/fuseki
docker-compose build --no-cache
## --volumes  # Remove volumes - destructive

rm logs/startup.log

docker-compose up -d

# docker-compose logs
## -f > logs/startup.log

================
File: restart-dogbot.sh
================
#!/bin/bash
echo "Restarting Docker services..."
docker-compose down
docker-compose up -d
echo "Services restarted. Now run the dogbot script."
echo "Use: docker exec -it tbox-ssh-server-1 bash -c 'cd /home/projects/tia/dogbot && ./start-dogbot.sh'"

================
File: restart.sh
================
#!/bin/bash

# chmod -R 777 ./data/fuseki

sudo systemctl stop tbox
cd ~/hyperdata/tbox # my local dir

docker-compose down

# docker-compose build --no-cache  # Rebuild without cache
# --volumes  # Remove volumes - destructive

docker-compose up -d

# docker-compose logs

================
File: simple-ssh-test.yml
================
version: "3"
services:
  ssh-test:
    image: alpine:latest
    ports:
      - "2323:22"
    command: >
      sh -c '
        apk add --update --no-cache openssh bash &&
        mkdir -p /var/run/sshd &&
        ssh-keygen -A &&
        echo "root:password" | chpasswd &&
        echo "PermitRootLogin yes" >> /etc/ssh/sshd_config &&
        echo "PasswordAuthentication yes" >> /etc/ssh/sshd_config &&
        /usr/sbin/sshd -D -e
      '

================
File: tbox.service
================
[Unit]
Description=TBox Docker Environment
Requires=docker.service
After=docker.service

[Service]
Type=oneshot
RemainAfterExit=yes
WorkingDirectory=/home/danny/hyperdata/tbox
ExecStart=/usr/bin/docker compose up -d
ExecStop=/usr/bin/docker compose down
TimeoutStartSec=0

[Install]
WantedBy=multi-user.target



================================================================
End of Codebase
================================================================
